{"timestamp": 1681099185.561127, "stored_source_code": "# declare a list tasks whose products you want to use as inputs\nupstream = None\nimport pandas as pd\nimport os\nimport xgboost as xgb\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom pathlib import Path\nfrom sklearn.utils import estimator_html_repr\nimport imgkit\nimport joblib\nimport imgkit\nfrom sklearn.metrics import DetCurveDisplay, RocCurveDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef generate_pipeline(X, model):\n    \"\"\"\n    \n    This function generates a pipeline with preprocessing, and the classifier.\n\n    Args:\n        X (pandas.DataFrame): DataFrame containing the features\n        model (sklearn model): Model to be used for classification\n\n    Returns:\n        pipeline (sklearn.pipeline.Pipeline): Pipeline with preprocessing,and the classifier\n    \"\"\"\n    \n    # Identify categorical and numerical columns\n    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n    numerical_cols = X.select_dtypes(exclude=['object']).columns.tolist()\n\n    # Define transformers for categorical and numerical columns\n    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n    numerical_transformer = StandardScaler()\n\n    # Create a column transformer\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, numerical_cols),\n            ('cat', categorical_transformer, categorical_cols)\n        ])\n    \n    # Create a pipeline with preprocessing, SMOTE, and the classifier\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                                  ('classifier', model)])\n    \n    return pipeline\ndef perform_cross_validation(X, y, pipeline, cv=5, scoring='accuracy', success_metric=0.81):\n\n    \"\"\"\n\n    This function performs cross-validation and prints the average accuracy.\n\n    Args:\n        X (pandas.DataFrame): DataFrame containing the features\n        y (pandas.Series): Series containing the target variable\n        pipeline (sklearn.pipeline.Pipeline): Pipeline with preprocessing,and the classifier\n        cv (int): Number of folds for cross-validation\n        scoring (str): Metric to be used for cross-validation\n\n    \"\"\"\n\n    # Perform 5-fold cross-validation\n    cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=scoring)\n\n    # Calculate the average accuracy\n    avg_accuracy = cv_scores.mean()\n\n    print(\"5-fold Cross-validation Accuracy:\", avg_accuracy)\n\n    if avg_accuracy >= success_metric:\n        print(\"Success: The average accuracy is above or equal to the success metric.\")\n    else:\n        print(\"Failure: The average accuracy is below the success metric.\")\ndef save_model(pipeline):\n\n    \"\"\"\n\n    This function saves the pipeline diagram and the pipeline sklearn object into the models folder\n\n    Args:\n        pipeline (sklearn.pipeline.Pipeline): Pipeline with preprocessing,and the classifier\n\n    \"\"\"\n\n    # Save the pipeline diagram to a file\n    result_path = os.path.abspath(os.path.join(os.getcwd(), 'models'))\n    with open(Path(result_path, \"pipeline_diagram.html\"), \"w\") as f:\n        f.write(estimator_html_repr(pipeline))\n\n    # Convert the HTML to an image\n    imgkit.from_file(str(Path(result_path, \"pipeline_diagram.html\")), str(Path(result_path, \"pipeline_diagram.png\")))\n\n    # Save the pipeline to a file\n    joblib.dump(pipeline, Path(result_path,\"pipeline.joblib\"))\ndef roc_curve_save_plot(pipeline, X_test, y_test):\n    \"\"\"\n    \n    This function generates a ROC curve and saves it to the figures folder.\n\n    Args:\n        pipeline (sklearn.pipeline.Pipeline): Pipeline with preprocessing,and the classifier\n        X_test (pandas.DataFrame): DataFrame containing the features of the test set\n        y_test (pandas.Series): Series containing the target variable of the test set\n\n    \"\"\"\n\n    fig, [ax_roc, ax_det] = plt.subplots(1, 2, figsize=(11, 5))\n\n    RocCurveDisplay.from_estimator(pipeline, X_test, y_test, ax=ax_roc)\n    DetCurveDisplay.from_estimator(pipeline, X_test, y_test, ax=ax_det)\n\n    ax_roc.set_title(\"Receiver Operating Characteristic (ROC) curves\")\n    ax_det.set_title(\"Detection Error Tradeoff (DET) curves\")\n\n    plt.legend()\n\n    # save the plot as a file\n    plt.savefig(os.path.abspath(os.path.join(os.getcwd(), 'reports', 'figures', \"roc\")))\ndef generate_feature_importances(pipeline,X, X_train, y_train):\n    \"\"\"\n    \n    This function generates a bar plot of feature importances and saves it to the figures folder.\n\n    Args:\n        pipeline (sklearn.pipeline.Pipeline): Pipeline with preprocessing,and the classifier\n        X (pandas.DataFrame): DataFrame containing the features\n        X_train (pandas.DataFrame): DataFrame containing the features of the training set\n        y_train (pandas.Series): Series containing the target variable of the training set\n\n    \"\"\"\n\n    # Train the pipeline\n    pipeline.fit(X_train, y_train)\n\n    # Get feature importances\n    importances = pipeline.named_steps['classifier'].feature_importances_\n\n    # Get feature names\n    numerical_feature_names = X.select_dtypes(exclude=['object']).columns.tolist()\n    categorical_feature_names = pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(input_features=X.select_dtypes(include=['object']).columns.tolist())\n\n    feature_names = numerical_feature_names + categorical_feature_names.tolist()\n\n    # Create a dataframe with feature names and importances\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})\n\n    # Sort the dataframe by feature importance\n    feature_importances = feature_importances.sort_values('importance', ascending=False).reset_index(drop=True)\n\n\n    # Plot the feature importances\n    plt.figure(figsize=(10, 10))\n    sns.barplot(data=feature_importances, x='importance', y='feature')\n    plt.title('Feature Importances')\n    plt.savefig(os.path.abspath(os.path.join(os.getcwd(), 'reports', 'figures', 'feature-importances.png')))\nif __name__==\"__main__\":\n\n    csv_path = os.path.abspath(os.path.join(os.getcwd(),  'data', 'raw', 'term-deposit-marketing-2020.csv'))\n    data = pd.read_csv(csv_path)\n\n    # Prepare target variable\n    data['y'] = data['y'].apply(lambda x: 1 if x == 'yes' else 0)\n\n    # Define feature columns and target column\n    X = data.drop(columns=['y','month','day','contact'])\n    y = data['y']\n\n    # Split the data into training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n    # Create a pipeline with preprocessing and XGBClassifier\n    model = xgb.XGBClassifier(random_state=42, )\n    pipeline = generate_pipeline(X, model)\n\n    # Perform cross-validation\n    perform_cross_validation(X_train, y_train, pipeline)\n\n    # Fit the model\n    pipeline.fit(X_train, y_train)\n\n    # Make predictions on the test set\n    y_pred = pipeline.predict(X_test)\n\n    # Evaluate the model\n    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n    # Generate ROC curve\n    roc_curve_save_plot(pipeline, X_test, y_test)\n\n    # Generate feature importances\n    generate_feature_importances(pipeline, X, X_train, y_train)\n\n    # Save the model\n    save_model(pipeline)\n", "params": {}}